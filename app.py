from __future__ import annotations

import json
import re
from collections import Counter
from pathlib import Path
from typing import Dict, List, Tuple

import requests
import streamlit as st
from openai import OpenAI


# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(page_title="ì–¼êµ´í˜• ê¸°ë°˜ í—¤ì–´ìŠ¤íƒ€ì¼ ì¶”ì²œ", layout="wide")
st.title("ì–¼êµ´í˜• ê¸°ë°˜ í—¤ì–´ìŠ¤íƒ€ì¼ + ë¯¸ìš©ì‹¤ ì¶”ì²œ")
st.caption("ìê°€ì§„ë‹¨ ì„ íƒ â†’ GPT ì¶”ì²œ í‚¤ì›Œë“œ 3ê°œ â†’ (ì›¹ í›„ê¸° ê¸°ë°˜ í™•ì¥ê²€ìƒ‰) â†’ ê·¼ì²˜ ë¯¸ìš©ì‹¤ ì¶”ì²œ")


# =========================
# âœ… ì‹¤ì¡´ í—¤ì–´ìŠ¤íƒ€ì¼/ì‹œìˆ  ìš©ì–´ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸
# =========================
STYLE_TERMS = [
    "ë‹¨ë°œ", "ì¤‘ë‹¨ë°œ", "ì¥ë°œ", "ìˆì»·", "ë³´ë¸Œì»·", "í—ˆì‰¬ì»·", "ë ˆì´ì–´ë“œì»·", "ìƒ¤ê¸°ì»·",
    "ë¦¬í”„ì»·", "ê°€ì¼ì»·", "íˆ¬ë¸”ëŸ­", "ëŒ„ë””ì»·", "í¬ë¡­ì»·",
    "Cì»¬íŒ", "Sì»¬íŒ", "ë¹Œë“œíŒ", "íˆí”¼íŒ", "ì‰ë„ìš°íŒ", "ê°€ë¥´ë§ˆíŒ", "ì• ì¦ˆíŒ",
    "ë¦¬ì  íŠ¸íŒ", "ì•„ì´ë¡±íŒ", "ë³¼ë¥¨íŒ", "ë””ì§€í„¸íŒ", "ì…‹íŒ…íŒ",
    "ë³¼ë¥¨ë§¤ì§", "ë§¤ì§", "ë§¤ì§ì…‹íŒ…",
    "ì—¼ìƒ‰", "íƒˆìƒ‰", "ë¿Œë¦¬ì—¼ìƒ‰", "ì˜´ë¸Œë ˆ", "ë°œë ˆì•„ì¥¬",
    "ì• ì‰¬ë¸Œë¼ìš´", "ì• ì‰¬ê·¸ë ˆì´", "ì• ì‰¬ë¸”ë£¨",
    "í•‘í¬ë¸Œë¼ìš´", "ì´ˆì½”ë¸Œë¼ìš´", "ì¹´í‚¤ë¸Œë¼ìš´",
    "ë‹¤ìš´íŒ", "ë‘í”¼ì¼€ì–´", "í´ë¦¬ë‹‰",
    "ì‹œìŠ¤ë£¨ë±…", "ì²˜í”¼ë±…", "í’€ë±…", "ì• êµë¨¸ë¦¬",
]
STYLE_STOP = {"ë¯¸ìš©ì‹¤", "í—¤ì–´", "ì»·", "íŒ", "ì—¼ìƒ‰"}

TONE_COLOR_RECO = {
    "ì›œ": ["ì´ˆì½”ë¸Œë¼ìš´", "ì¹´í‚¤ë¸Œë¼ìš´", "í•‘í¬ë¸Œë¼ìš´"],
    "ì¿¨": ["ì• ì‰¬ë¸Œë¼ìš´", "ì• ì‰¬ê·¸ë ˆì´", "ì• ì‰¬ë¸”ë£¨"],
}

MOOD_CHOICES = ["ì²­ìˆœ", "ì‹œí¬", "í™í•œ", "ë‹¨ì •í•œ", "ê·€ì—¬ìš´", "ì„¸ë ¨ëœ", "ë™ì•ˆ ëŠë‚Œ", "ì„±ìˆ™í•œ ëŠë‚Œ"]


# =========================
# í•„ìš”í•œ ì´ë¯¸ì§€ íŒŒì¼ ì²´í¬
# =========================
REQUIRED_IMAGES = [
    "ì›œí†¤.jpg",
    "ì¿¨í†¤.jpg",
    "ê³„ë€í˜•.png",
    "ë§ˆë¦„ëª¨í˜•.png",
    "í•˜íŠ¸í˜•.png",
    "ë•…ì½©í˜•.png",
    "ìœ¡ê°í˜•.png",
    "ë‘¥ê·¼í˜•.png",
    "ì§ëª¨.png",
    "ê³±ìŠ¬.png",
]


def must_exist(path: str) -> None:
    if not Path(path).exists():
        st.error(
            f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”: {path}\n\n"
            f"app.pyì™€ ê°™ì€ í´ë”ì— '{path}' íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
        )
        st.stop()


for p in REQUIRED_IMAGES:
    must_exist(p)


# =========================
# API Key ì…ë ¥
# =========================
st.sidebar.header("ğŸ”‘ API Key ì„¤ì •")
st.sidebar.info("ğŸ” í‚¤ëŠ” ì„œë²„ì— ì €ì¥ë˜ì§€ ì•Šìœ¼ë©°, ìƒˆë¡œê³ ì¹¨í•˜ë©´ ë‹¤ì‹œ ì…ë ¥í•´ì•¼ í•  ìˆ˜ ìˆì–´ìš”.")

if "KAKAO_REST_API_KEY" not in st.session_state:
    st.session_state["KAKAO_REST_API_KEY"] = (st.secrets.get("KAKAO_REST_API_KEY", "") or "").strip()

kakao_input = st.sidebar.text_input(
    "Kakao REST API Key (í•„ìˆ˜)",
    value=st.session_state["KAKAO_REST_API_KEY"],
    type="password",
)
st.session_state["KAKAO_REST_API_KEY"] = (kakao_input or "").strip()
KAKAO_REST_API_KEY = st.session_state["KAKAO_REST_API_KEY"]

if "OPENAI_API_KEY" not in st.session_state:
    st.session_state["OPENAI_API_KEY"] = (st.secrets.get("OPENAI_API_KEY", "") or "").strip()

openai_input = st.sidebar.text_input(
    "OpenAI API Key (í•„ìˆ˜)",
    value=st.session_state["OPENAI_API_KEY"],
    type="password",
)
st.session_state["OPENAI_API_KEY"] = (openai_input or "").strip()
OPENAI_API_KEY = st.session_state["OPENAI_API_KEY"]

st.sidebar.caption("Kakao í‚¤ê°€ ì—†ìœ¼ë©´ ë¯¸ìš©ì‹¤ ê²€ìƒ‰ì´ ë¶ˆê°€í•©ë‹ˆë‹¤. OpenAI í‚¤ê°€ ì—†ìœ¼ë©´ GPT ì¶”ì²œ/í›„ê¸° ë¶„ì„ì´ ë¶ˆê°€í•©ë‹ˆë‹¤.")

if not KAKAO_REST_API_KEY:
    st.warning("ì¹´ì¹´ì˜¤ REST API Keyë¥¼ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

if not OPENAI_API_KEY:
    st.warning("OpenAI API Keyë¥¼ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()


# =========================
# UI ì¹´ë“œ ë Œë” ìœ í‹¸
# =========================
def select_card(
    *,
    title: str,
    image_path: str,
    button_label: str,
    on_click_value: str,
    session_key: str,
    button_key: str,
    desc_md: str | None = None,
    img_width: int = 160,
    selected: bool = False,
) -> None:
    st.subheader(title)
    st.image(image_path, width=img_width)
    if desc_md:
        st.markdown(desc_md)

    btn_type = "primary" if selected else "secondary"
    if st.button(button_label, key=button_key, use_container_width=True, type=btn_type):
        st.session_state[session_key] = on_click_value
        st.rerun()


# =========================
# ì–¼êµ´í˜• íŒíŠ¸ ìš©ì–´
# =========================
FACE_SHAPE_TO_KEYWORDS: Dict[str, List[str]] = {
    "ë‘¥ê·¼ì–¼êµ´í˜•": ["ë ˆì´ì–´ë“œì»·", "Sì»¬íŒ", "Cì»¬íŒ", "ì‹œìŠ¤ë£¨ë±…"],
    "ê¸´ì–¼êµ´í˜•": ["ë‹¨ë°œ", "ì¤‘ë‹¨ë°œ", "Cì»¬íŒ", "íˆí”¼íŒ"],
    "ê°ì§„ ì–¼êµ´í˜•": ["ë ˆì´ì–´ë“œì»·", "Sì»¬íŒ", "ë³¼ë¥¨íŒ"],
    "ì—­ì‚¼ê°í˜• ì–¼êµ´": ["ë‹¨ë°œ", "Cì»¬íŒ", "ë³¼ë¥¨ë§¤ì§"],
    "ê³„ë€í˜• ì–¼êµ´": ["ë‹¨ë°œ", "ì¤‘ë‹¨ë°œ", "ë ˆì´ì–´ë“œì»·", "Sì»¬íŒ"],
}

APP_FACE_TO_RECO_FACE: Dict[str, str] = {
    "ë‘¥ê·¼í˜•": "ë‘¥ê·¼ì–¼êµ´í˜•",
    "ê³„ë€í˜•": "ê³„ë€í˜• ì–¼êµ´",
    "í•˜íŠ¸í˜•": "ì—­ì‚¼ê°í˜• ì–¼êµ´",
    "ìœ¡ê°í˜•": "ê°ì§„ ì–¼êµ´í˜•",
    "ë§ˆë¦„ëª¨í˜•": "ê¸´ì–¼êµ´í˜•",
    "ë•…ì½©í˜•": "ê°ì§„ ì–¼êµ´í˜•",
}


def build_auto_terms(app_face_shape: str, preferred_length: str, mood: str, max_terms: int = 6) -> List[str]:
    reco_face = APP_FACE_TO_RECO_FACE.get(app_face_shape, "ê³„ë€í˜• ì–¼êµ´")
    terms = FACE_SHAPE_TO_KEYWORDS.get(reco_face, ["ë ˆì´ì–´ë“œì»·", "Cì»¬íŒ", "Sì»¬íŒ"]).copy()

    if preferred_length == "ì§§ê²Œ":
        terms = ["ìˆì»·", "ë³´ë¸Œì»·", *terms]
    elif preferred_length == "ê¸¸ê²Œ":
        terms = ["ì¤‘ë‹¨ë°œ", "ì¥ë°œ", *terms]

    if mood in {"ë‹¨ì •í•œ", "ì„¸ë ¨ëœ"}:
        terms.append("Cì»¬íŒ")
    if mood in {"í™í•œ", "ì‹œí¬"}:
        terms.extend(["í—ˆì‰¬ì»·", "ë ˆì´ì–´ë“œì»·"])
    if mood in {"ê·€ì—¬ìš´", "ì²­ìˆœ", "ë™ì•ˆ ëŠë‚Œ"}:
        terms.extend(["ì‹œìŠ¤ë£¨ë±…", "Sì»¬íŒ"])

    uniq = []
    seen = set()
    for t in terms:
        if t in STYLE_TERMS and t not in seen:
            seen.add(t)
            uniq.append(t)
    return uniq[:max_terms]


# =========================
# GPT ì¶”ì²œ(3ê°œ) - ì‹¤ì¡´ ìš©ì–´ë§Œ
# =========================
def safe_json_extract(text: str) -> str:
    raw = (text or "").strip()
    raw = re.sub(r"^```(?:json)?\s*", "", raw, flags=re.IGNORECASE)
    raw = re.sub(r"\s*```$", "", raw)
    m = re.search(r"\{.*\}", raw, flags=re.DOTALL)
    return m.group(0) if m else raw


def normalize_query(q: str) -> str:
    q = (q or "").replace("\n", " ").strip()
    q = re.sub(r"\s+", " ", q)
    if "ë¯¸ìš©ì‹¤" not in q:
        q = f"{q} ë¯¸ìš©ì‹¤".strip()
    return q


def enforce_style_whitelist(query: str, allowed_terms: List[str]) -> str:
    q = query.replace("ë¯¸ìš©ì‹¤", "").strip()
    terms_sorted = sorted(allowed_terms, key=len, reverse=True)
    picked: List[str] = []
    for t in terms_sorted:
        if t in q and t not in picked:
            picked.append(t)

    if not picked:
        picked = [allowed_terms[0]] if allowed_terms else ["ë ˆì´ì–´ë“œì»·"]

    picked = picked[:2]
    return normalize_query(" ".join(picked))


def make_queries_with_openai(
    *,
    api_key: str,
    tone: str,
    face_shape: str,
    hair_type: str,
    preferred_length: str,
    mood: str,
    current_hair_length: str,
    bangs_status: str,
    styling_level: str,
    hint_terms: List[str],
) -> Tuple[List[str], List[str]]:
    client = OpenAI(api_key=api_key)

    prompt = f"""
ë„ˆëŠ” í•œêµ­ í—¤ì–´ë””ìì´ë„ˆì•¼.
ì‚¬ìš©ì ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹´ì¹´ì˜¤ ë¡œì»¬ì—ì„œ ê²€ìƒ‰ ê°€ëŠ¥í•œ "ë¯¸ìš©ì‹¤ ê²€ìƒ‰ í‚¤ì›Œë“œ 3ê°œ"ë¥¼ ì¶”ì²œí•´ì¤˜.

ì¤‘ìš” ê·œì¹™:
- ê° queryì—ëŠ” ë°˜ë“œì‹œ 'ë¯¸ìš©ì‹¤' í¬í•¨
- queryëŠ” ë°˜ë“œì‹œ í—ˆìš©ëœ ìŠ¤íƒ€ì¼ ìš©ì–´ ëª©ë¡ì—ì„œë§Œ ê³¨ë¼ ì¡°í•©
- í—ˆìš© ëª©ë¡ ë°– ë‹¨ì–´ ì ˆëŒ€ ê¸ˆì§€
- (ìŠ¤íƒ€ì¼ìš©ì–´ 1~2ê°œ + 'ë¯¸ìš©ì‹¤')ë¡œ ê°„ê²°í•˜ê²Œ

[ì‚¬ìš©ì ì •ë³´]
- tone: {tone}
- face_shape: {face_shape}
- hair_type: {hair_type}
- preferred_length: {preferred_length}
- mood: {mood}
- current_hair_length: {current_hair_length}
- bangs_status: {bangs_status}
- styling_level: {styling_level}

[ì¶”ì²œ íŒíŠ¸]
{json.dumps(hint_terms, ensure_ascii=False)}

[í—ˆìš©ëœ ìŠ¤íƒ€ì¼ ìš©ì–´ ëª©ë¡]
{json.dumps(STYLE_TERMS, ensure_ascii=False)}

ì¶œë ¥(JSONë§Œ):
{{
  "recommendations": [
    {{"query":"... ë¯¸ìš©ì‹¤","reason":"..."}},
    {{"query":"... ë¯¸ìš©ì‹¤","reason":"..."}},
    {{"query":"... ë¯¸ìš©ì‹¤","reason":"..."}}
  ]
}}
""".strip()

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
    )

    raw = safe_json_extract(resp.choices[0].message.content or "")
    queries: List[str] = []
    reasons: List[str] = []

    try:
        obj = json.loads(raw)
        recs = obj.get("recommendations", [])
        if isinstance(recs, list):
            for it in recs:
                if isinstance(it, dict):
                    queries.append(str(it.get("query", "")).strip())
                    reasons.append(str(it.get("reason", "")).strip())
    except Exception:
        queries, reasons = [], []

    final_q: List[str] = []
    final_r: List[str] = []
    seen = set()

    for q, r in zip(queries, reasons):
        fixed = enforce_style_whitelist(q, allowed_terms=STYLE_TERMS)
        if fixed and fixed not in seen:
            seen.add(fixed)
            final_q.append(fixed)
            final_r.append(r)
        if len(final_q) >= 3:
            break

    if len(final_q) < 3:
        fallback_pool = []
        for t in hint_terms:
            if t in STYLE_TERMS:
                fallback_pool.append(normalize_query(f"{t} ë¯¸ìš©ì‹¤"))
        for t in STYLE_TERMS:
            fallback_pool.append(normalize_query(f"{t} ë¯¸ìš©ì‹¤"))

        for q in fallback_pool:
            if q not in seen:
                seen.add(q)
                final_q.append(q)
                final_r.append("í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ë³´ì™„ ì¶”ì²œ")
            if len(final_q) >= 3:
                break

    return final_q[:3], final_r[:3]


# =========================
# Kakao Local + Kakao Search ìœ í‹¸
# =========================
def kakao_headers() -> Dict[str, str]:
    return {"Authorization": f"KakaoAK {KAKAO_REST_API_KEY}"}


@st.cache_data(show_spinner=False, ttl=3600)
def kakao_address_to_xy(address: str) -> Tuple[float, float]:
    url = "https://dapi.kakao.com/v2/local/search/address.json"
    r = requests.get(url, headers=kakao_headers(), params={"query": address}, timeout=10)
    r.raise_for_status()
    docs = r.json().get("documents", [])
    if not docs:
        raise ValueError("ì£¼ì†Œë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. ë” ìì„¸í•œ ì£¼ì†Œë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    return float(docs[0]["x"]), float(docs[0]["y"])


@st.cache_data(show_spinner=False, ttl=600)
def kakao_keyword_search(query: str, x: float, y: float, radius_m: int = 3000, size: int = 15, page: int = 1) -> List[dict]:
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    params = {
        "query": query,
        "x": str(x),
        "y": str(y),
        "radius": str(radius_m),
        "size": str(size),
        "page": str(page),
        "sort": "distance",
    }
    r = requests.get(url, headers=kakao_headers(), params=params, timeout=10)
    r.raise_for_status()
    return r.json().get("documents", [])


def strip_html(text: str) -> str:
    text = re.sub(r"<[^>]+>", " ", text)
    return re.sub(r"\s+", " ", text).strip()


@st.cache_data(show_spinner=False, ttl=1800)
def kakao_search_blog(query: str, size: int = 5) -> List[dict]:
    url = "https://dapi.kakao.com/v2/search/blog"
    params = {"query": query, "size": size, "sort": "accuracy"}
    r = requests.get(url, headers=kakao_headers(), params=params, timeout=10)
    r.raise_for_status()
    return r.json().get("documents", [])


@st.cache_data(show_spinner=False, ttl=1800)
def kakao_search_web(query: str, size: int = 5) -> List[dict]:
    url = "https://dapi.kakao.com/v2/search/web"
    params = {"query": query, "size": size, "sort": "accuracy"}
    r = requests.get(url, headers=kakao_headers(), params=params, timeout=10)
    r.raise_for_status()
    return r.json().get("documents", [])


def build_review_snippet_for_place(place_name: str, area_hint: str) -> str:
    q = f"{place_name} {area_hint} ë¯¸ìš©ì‹¤ í›„ê¸° íŒ ì»·"
    try:
        blog_docs = kakao_search_blog(q, size=5)
    except Exception:
        blog_docs = []
    try:
        web_docs = kakao_search_web(q, size=5)
    except Exception:
        web_docs = []

    parts: List[str] = []
    for d in blog_docs[:5]:
        parts.append(f"[ë¸”ë¡œê·¸] {strip_html(d.get('title', ''))} - {strip_html(d.get('contents', ''))}")
    for d in web_docs[:5]:
        parts.append(f"[ì›¹] {strip_html(d.get('title', ''))} - {strip_html(d.get('contents', ''))}")

    return " | ".join([p for p in parts if p.strip()])[:2500]


def analyze_styles_from_reviews_with_openai(
    *,
    api_key: str,
    chosen_query: str,
    places: List[dict],
    review_snippets: Dict[str, str],
) -> Dict[str, Dict]:
    client = OpenAI(api_key=api_key)

    payload = []
    for p in places:
        name = p.get("place_name", "")
        addr = p.get("road_address_name", "") or p.get("address_name", "")
        payload.append({"name": name, "address": addr, "snippet": review_snippets.get(name, "")})

    prompt = f"""
ë„ˆëŠ” í•œêµ­ í—¤ì–´/ë¯¸ìš©ì‹¤ ë¦¬ë·° ë¶„ì„ê°€ì•¼.
ì‚¬ìš©ìì˜ ì˜ë„ í‚¤ì›Œë“œì™€ ê° ë¯¸ìš©ì‹¤ì˜ ì›¹ í›„ê¸° ìŠ¤ë‹ˆí«ì„ ë³´ê³ ,
ê° ë¯¸ìš©ì‹¤ì´ ìœ ëª…í•œ ì‹œìˆ /ìŠ¤íƒ€ì¼ íƒœê·¸ë¥¼ ë½‘ì•„ì¤˜.

ê·œì¹™:
- tagsëŠ” ë°˜ë“œì‹œ ì•„ë˜ í—ˆìš© ëª©ë¡ì—ì„œë§Œ ì„ íƒ
- snippetì´ ë¹ˆ ê²½ìš° tags=[], summary="ì •ë³´ ë¶€ì¡±"
- JSONë§Œ ì¶œë ¥

[chosen_query] {chosen_query}
[í—ˆìš©ëœ ìŠ¤íƒ€ì¼ ìš©ì–´ ëª©ë¡] {json.dumps(STYLE_TERMS, ensure_ascii=False)}
[ë°ì´í„°] {json.dumps(payload, ensure_ascii=False)}

ì¶œë ¥:
{{"salons":[{{"name":"...","tags":["..."],"summary":"..."}}, ...]}}
""".strip()

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
    )

    raw = safe_json_extract(resp.choices[0].message.content or "")
    result: Dict[str, Dict] = {}
    try:
        obj = json.loads(raw)
        salons = obj.get("salons", [])
        if isinstance(salons, list):
            for s in salons:
                if not isinstance(s, dict):
                    continue
                name = str(s.get("name", "")).strip()
                tags = s.get("tags", [])
                summary = str(s.get("summary", "")).strip()
                if isinstance(tags, list):
                    tags = [str(t).strip() for t in tags if str(t).strip() in STYLE_TERMS]
                else:
                    tags = []
                if name:
                    result[name] = {"tags": tags[:6], "summary": summary}
    except Exception:
        result = {}
    return result


def build_expanded_queries_from_tags(chosen_query: str, style_map: Dict[str, Dict], max_queries: int = 3) -> List[str]:
    counter = Counter()
    for v in style_map.values():
        for t in v.get("tags", []):
            if t and t not in STYLE_STOP:
                counter[t] += 1

    ranked = [t for t, _ in counter.most_common()]
    chosen_words = set(re.findall(r"[ê°€-í£A-Za-z0-9]+", chosen_query))
    ranked = [t for t in ranked if t not in chosen_words]

    expanded = [normalize_query(f"{t} ë¯¸ìš©ì‹¤") for t in ranked[:max_queries]]

    uniq, seen = [], set()
    for q in expanded:
        if q not in seen:
            seen.add(q)
            uniq.append(q)
    return uniq[:max_queries]


def merge_places(*lists: List[dict]) -> List[dict]:
    merged = []
    seen = set()
    for lst in lists:
        for p in lst:
            key = p.get("place_url") or (p.get("place_name", "") + "|" + (p.get("road_address_name", "") or p.get("address_name", "")))
            if key and key not in seen:
                seen.add(key)
                merged.append(p)
    return merged


def build_fallback_queries(chosen_query: str) -> List[str]:
    q = (chosen_query or "").strip()
    q_no = q.replace("ë¯¸ìš©ì‹¤", "").strip()
    fallbacks = [q] if q else []
    if q_no:
        fallbacks.extend([q_no, f"{q_no} í—¤ì–´", f"{q_no} í—¤ì–´ìƒµ"])
    fallbacks.append("ë¯¸ìš©ì‹¤")

    uniq, seen = [], set()
    for x in fallbacks:
        x = re.sub(r"\s+", " ", x).strip()
        if x and x not in seen:
            seen.add(x)
            uniq.append(x)
    return uniq


def search_salons_with_fallback(*, chosen_query: str, x: float, y: float, radius_m: int, size: int = 15) -> Tuple[List[dict], str, int]:
    queries = build_fallback_queries(chosen_query)
    radius_try = [radius_m, min(radius_m * 2, 20000)]

    for r in radius_try:
        for q in queries:
            res1 = kakao_keyword_search(query=q, x=x, y=y, radius_m=r, size=size, page=1)
            res2 = kakao_keyword_search(query=q, x=x, y=y, radius_m=r, size=size, page=2) if res1 else []
            res = merge_places(res1, res2)
            if res:
                return res, q, r

    return [], queries[0] if queries else chosen_query, radius_m


# =========================
# 1) ì„ íƒ UI
# =========================
keys = (
    "tone",
    "face_shape",
    "hair_type",
    "preferred_length",
    "mood",
    "current_hair_length",
    "bangs_status",
    "styling_level",
)
for k in keys:
    if k not in st.session_state:
        st.session_state[k] = None

steps_done = sum(1 for k in keys if st.session_state[k] is not None)
st.progress(steps_done / len(keys))

st.header("1) ì›œí†¤ / ì¿¨í†¤ ì„ íƒ (ì—¼ìƒ‰ ì»¬ëŸ¬ ì¶”ì²œìš©)")
tone_cols = st.columns(2, gap="large")
with tone_cols[0]:
    select_card(
        title="ì›œí†¤",
        image_path="ì›œí†¤.jpg",
        desc_md="**ìê°€ì§„ë‹¨**\n1. íŒ”ëª© í˜ˆê´€ì´ **ì´ˆë¡ë¹›**\n2. í”¼ë¶€ì— **ë…¸ë€ê¸°**ê°€ ë§ìŒ",
        button_label="âœ… ì›œí†¤ ì„ íƒ",
        on_click_value="ì›œ",
        session_key="tone",
        button_key="btn_tone_warm",
        img_width=130,
        selected=(st.session_state["tone"] == "ì›œ"),
    )
with tone_cols[1]:
    select_card(
        title="ì¿¨í†¤",
        image_path="ì¿¨í†¤.jpg",
        desc_md="**ìê°€ì§„ë‹¨**\n1. íŒ”ëª© í˜ˆê´€ì´ **íŒŒë€ë¹›**\n2. í”¼ë¶€ì— **ë¶‰ì€ê¸°**ê°€ ë§ìŒ",
        button_label="âœ… ì¿¨í†¤ ì„ íƒ",
        on_click_value="ì¿¨",
        session_key="tone",
        button_key="btn_tone_cool",
        img_width=130,
        selected=(st.session_state["tone"] == "ì¿¨"),
    )
if st.button("tone ì´ˆê¸°í™”", key="reset_tone", type="secondary"):
    st.session_state["tone"] = None
    st.rerun()

st.divider()

st.header("2) ì–¼êµ´í˜• ì„ íƒ")
FACE_CHOICES = [
    ("ê³„ë€í˜•", "ê³„ë€í˜•.png", "ê´‘ëŒ€ X, í„± X - ê´‘ëŒ€ì™€ í„± ê³¨ê²©ì´ ë‘ë“œëŸ¬ì§€ì§€ ì•ŠìŒ"),
    ("ë§ˆë¦„ëª¨í˜•", "ë§ˆë¦„ëª¨í˜•.png", "ê´‘ëŒ€ O, í„± X - ê´‘ëŒ€ê°€ ë¶€ê°ë¨"),
    ("í•˜íŠ¸í˜•", "í•˜íŠ¸í˜•.png", "ê´‘ëŒ€ O í„± â–³ - ê´‘ëŒ€ê°€ ë„“ê³  í„±ì´ ìƒëŒ€ì ìœ¼ë¡œ ì¢ìŒ"),
    ("ë•…ì½©í˜•", "ë•…ì½©í˜•.png", "ê´‘ëŒ€ O í„± O - ê´‘ëŒ€ì™€ í„± ê³¨ê²©ì´ ëª¨ë‘ ìˆìŒ"),
    ("ìœ¡ê°í˜•", "ìœ¡ê°í˜•.png", "ê´‘ëŒ€ X í„± O - í„±ì„ ì´ ê°ì§„ í¸"),
    ("ë‘¥ê·¼í˜•", "ë‘¥ê·¼í˜•.png", "ê´‘ëŒ€ X í„± X - ì „ì²´ì ìœ¼ë¡œ ë‘¥ê·¼ ì¸ìƒ"),
]
rows = [FACE_CHOICES[:3], FACE_CHOICES[3:]]
for r_i, r in enumerate(rows):
    cols = st.columns(3, gap="large")
    for col, (name, img, desc) in zip(cols, r):
        with col:
            select_card(
                title=name,
                image_path=img,
                desc_md=desc,
                button_label=f"âœ… {name} ì„ íƒ",
                on_click_value=name,
                session_key="face_shape",
                button_key=f"btn_face_{r_i}_{name}",
                img_width=160,
                selected=(st.session_state["face_shape"] == name),
            )
if st.button("face_shape ì´ˆê¸°í™”", key="reset_face", type="secondary"):
    st.session_state["face_shape"] = None
    st.rerun()

st.divider()

st.header("3) ëª¨ë°œ íƒ€ì… ì„ íƒ")
hair_cols = st.columns(2, gap="large")
with hair_cols[0]:
    select_card(
        title="ì§ëª¨",
        image_path="ì§ëª¨.png",
        button_label="âœ… ì§ëª¨ ì„ íƒ",
        on_click_value="ì§ëª¨",
        session_key="hair_type",
        button_key="btn_hair_straight",
        img_width=100,
        selected=(st.session_state["hair_type"] == "ì§ëª¨"),
    )
with hair_cols[1]:
    select_card(
        title="ê³±ìŠ¬",
        image_path="ê³±ìŠ¬.png",
        button_label="âœ… ê³±ìŠ¬ ì„ íƒ",
        on_click_value="ê³±ìŠ¬",
        session_key="hair_type",
        button_key="btn_hair_curly",
        img_width=100,
        selected=(st.session_state["hair_type"] == "ê³±ìŠ¬"),
    )
if st.button("hair_type ì´ˆê¸°í™”", key="reset_hair", type="secondary"):
    st.session_state["hair_type"] = None
    st.rerun()

st.divider()

st.header("4) ê¸°ì¥ ì„ í˜¸ë„ ì„ íƒ")
st.session_state["preferred_length"] = st.radio(
    "ì›í•˜ëŠ” ì „ì²´ ê¸°ì¥ ëŠë‚Œì„ ì„ íƒí•˜ì„¸ìš”.",
    options=["ì§§ê²Œ", "ì¤‘ê°„", "ê¸¸ê²Œ"],
    index=["ì§§ê²Œ", "ì¤‘ê°„", "ê¸¸ê²Œ"].index(st.session_state["preferred_length"]) if st.session_state["preferred_length"] else 1,
    horizontal=True,
)

st.header("5) ì›í•˜ëŠ” ì´ë¯¸ì§€/ë¬´ë“œ ì„ íƒ")
st.session_state["mood"] = st.selectbox(
    "ì›í•˜ëŠ” ë¶„ìœ„ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš”.",
    options=MOOD_CHOICES,
    index=MOOD_CHOICES.index(st.session_state["mood"]) if st.session_state["mood"] in MOOD_CHOICES else 0,
)

st.header("6) í˜„ì¬ ë¨¸ë¦¬ ê¸¸ì´")
length_options = ["ìˆ", "ë‹¨ë°œ", "ì¤‘ë‹¨ë°œ", "ì¥ë°œ"]
st.session_state["current_hair_length"] = st.radio(
    "í˜„ì¬ ê¸¸ì´ë¥¼ ì„ íƒí•˜ì„¸ìš”.",
    options=length_options,
    index=length_options.index(st.session_state["current_hair_length"]) if st.session_state["current_hair_length"] in length_options else 1,
    horizontal=True,
)

st.header("7) ì•ë¨¸ë¦¬ ìœ ë¬´")
bang_options = ["ì•ë¨¸ë¦¬ ìˆìŒ", "ì•ë¨¸ë¦¬ ì—†ìŒ", "ë§Œë“¤ ì˜í–¥ ìˆìŒ"]
st.session_state["bangs_status"] = st.radio(
    "ì•ë¨¸ë¦¬ ìƒíƒœë¥¼ ì„ íƒí•˜ì„¸ìš”.",
    options=bang_options,
    index=bang_options.index(st.session_state["bangs_status"]) if st.session_state["bangs_status"] in bang_options else 0,
    horizontal=True,
)

st.header("8) ìŠ¤íƒ€ì¼ë§ ë‚œì´ë„ ì„ í˜¸")
styling_options = ["ì†ì§ˆ ê±°ì˜ ì•ˆ í•¨", "ë³´í†µ", "ìŠ¤íƒ€ì¼ë§ ê°€ëŠ¥"]
st.session_state["styling_level"] = st.radio(
    "í‰ì†Œ ìŠ¤íƒ€ì¼ë§ ê°€ëŠ¥ ìˆ˜ì¤€ì„ ì„ íƒí•˜ì„¸ìš”.",
    options=styling_options,
    index=styling_options.index(st.session_state["styling_level"]) if st.session_state["styling_level"] in styling_options else 1,
    horizontal=True,
)

st.divider()


# =========================
# 5) GPT ì¶”ì²œ(3ê°œ)
# =========================
st.header("9) GPT ì¶”ì²œ í‚¤ì›Œë“œ 3ê°œ(ì‹¤ì¡´ ìŠ¤íƒ€ì¼ ìš©ì–´)")

tone = st.session_state["tone"]
face_shape = st.session_state["face_shape"]
hair_type = st.session_state["hair_type"]
preferred_length = st.session_state["preferred_length"]
mood = st.session_state["mood"]
current_hair_length = st.session_state["current_hair_length"]
bangs_status = st.session_state["bangs_status"]
styling_level = st.session_state["styling_level"]

m1, m2, m3, m4 = st.columns(4)
m1.metric("tone", tone or "-")
m2.metric("face_shape", face_shape or "-")
m3.metric("hair_type", hair_type or "-")
m4.metric("mood", mood or "-")

if tone:
    st.info(f"ğŸ¨ í†¤ ê¸°ë°˜ ì—¼ìƒ‰ ì»¬ëŸ¬ ì¶”ì²œ: {', '.join(TONE_COLOR_RECO.get(tone, []))}")

all_selected = all([
    tone,
    face_shape,
    hair_type,
    preferred_length,
    mood,
    current_hair_length,
    bangs_status,
    styling_level,
])

hint_terms = build_auto_terms(face_shape or "", preferred_length or "ì¤‘ê°„", mood or "ë‹¨ì •í•œ")

if "gpt_queries" not in st.session_state:
    st.session_state["gpt_queries"] = []
if "gpt_reasons" not in st.session_state:
    st.session_state["gpt_reasons"] = []

gpt_btn = st.button("âœ¨ GPT ì¶”ì²œ ê²€ìƒ‰ì–´ 3ê°œ ë§Œë“¤ê¸°", key="btn_make_gpt_queries", use_container_width=True, disabled=(not all_selected))

if gpt_btn:
    try:
        with st.spinner("GPTê°€ ê²€ìƒ‰ì–´ 3ê°œë¥¼ ì¶”ì²œí•˜ëŠ” ì¤‘..."):
            qs, rs = make_queries_with_openai(
                api_key=OPENAI_API_KEY,
                tone=tone,
                face_shape=face_shape,
                hair_type=hair_type,
                preferred_length=preferred_length,
                mood=mood,
                current_hair_length=current_hair_length,
                bangs_status=bangs_status,
                styling_level=styling_level,
                hint_terms=hint_terms,
            )
            st.session_state["gpt_queries"] = qs
            st.session_state["gpt_reasons"] = rs
    except Exception as e:
        st.error(f"GPT í˜¸ì¶œ ì˜¤ë¥˜: {e}")

chosen_query = ""
chosen_idx = 0
if st.session_state["gpt_queries"]:
    options = [f"ğŸ¤– GPT ì¶”ì²œ {i + 1}: {q}" for i, q in enumerate(st.session_state["gpt_queries"])]
    chosen = st.radio("ì•„ë˜ GPT ì¶”ì²œ í‚¤ì›Œë“œ(3ê°œ) ì¤‘ í•˜ë‚˜ë¡œ 1ì°¨ ê²€ìƒ‰í•©ë‹ˆë‹¤.", options=options, index=0, key="auto_query_radio")
    chosen_idx = options.index(chosen)
    chosen_query = st.session_state["gpt_queries"][chosen_idx]

    reason = st.session_state["gpt_reasons"][chosen_idx] if chosen_idx < len(st.session_state["gpt_reasons"]) else ""
    if reason:
        st.info(f"GPT ì¶”ì²œ ì´ìœ : {reason}")
else:
    st.warning("ì•„ì§ GPT ì¶”ì²œ í‚¤ì›Œë“œê°€ ì—†ì–´ìš”. ìœ„ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìƒì„±í•´ì£¼ì„¸ìš”.")

st.divider()


# =========================
# 6) Kakao Local ê²€ìƒ‰ + ì›¹í›„ê¸° ê¸°ë°˜ í™•ì¥ê²€ìƒ‰
# =========================
st.header("10) (ì›¹ í›„ê¸° ë¶„ì„)ìœ¼ë¡œ ìœ ëª… ìŠ¤íƒ€ì¼ì„ ì°¾ê³  í™•ì¥ ê²€ìƒ‰í•˜ê¸°")

address = st.text_input("ë‚´ ìœ„ì¹˜(ì£¼ì†Œ)ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: ì„œìš¸ì‹œ ì„œëŒ€ë¬¸êµ¬ ì—°ì„¸ë¡œ 50)", key="input_address")
radius = st.slider("ê²€ìƒ‰ ë°˜ê²½(ë¯¸í„°)", 500, 10000, 3000, step=500, key="radius_slider")

use_review_expansion = st.toggle("ì›¹ í›„ê¸° ê¸°ë°˜ í™•ì¥ê²€ìƒ‰ ì‚¬ìš©", value=True)
topn_for_review = st.slider("í›„ê¸° ë¶„ì„í•  í›„ë³´ ê°œìˆ˜(ìƒìœ„ Nê°œ)", 3, 15, 10, step=1)
expansion_queries_n = st.slider("í™•ì¥ ê²€ìƒ‰ì–´ ê°œìˆ˜", 1, 3, 3, step=1)

auto_fallback = st.toggle("ê²€ìƒ‰ì–´ ìë™ ì™„í™”(fallback) ì‚¬ìš©", value=True)
result_size = st.slider("ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜(size)", 5, 20, 15, step=1)

find_btn = st.button("ğŸ“ (1ì°¨+í™•ì¥) ê·¼ì²˜ ë¯¸ìš©ì‹¤ ì°¾ê¸°", key="btn_find_salon", use_container_width=True)

if find_btn:
    if not all_selected:
        st.error("ëª¨ë“  ì‚¬ìš©ì ì„ íƒ í•­ëª©ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        st.stop()
    if not st.session_state["gpt_queries"] or not chosen_query.strip():
        st.error("ë¨¼ì € GPT ì¶”ì²œ ê²€ìƒ‰ì–´(3ê°œ)ë¥¼ ìƒì„±í•˜ê³  í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        st.stop()
    if not address.strip():
        st.error("ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    try:
        with st.spinner("ì£¼ì†Œë¥¼ ì¢Œí‘œë¡œ ë³€í™˜ ì¤‘..."):
            x, y = kakao_address_to_xy(address.strip())

        with st.spinner("1ì°¨: ë¯¸ìš©ì‹¤ ê²€ìƒ‰ ì¤‘..."):
            if auto_fallback:
                base_results, used_q, used_r = search_salons_with_fallback(chosen_query=chosen_query, x=x, y=y, radius_m=radius, size=result_size)
            else:
                base_results = kakao_keyword_search(query=chosen_query, x=x, y=y, radius_m=radius, size=result_size, page=1)
                used_q, used_r = chosen_query, radius

        if not base_results:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ìš”. ìë™ ì™„í™” ì˜µì…˜ì„ ì¼œê±°ë‚˜ ë°˜ê²½ì„ ëŠ˜ë ¤ë³´ì„¸ìš”.")
            st.stop()

        st.success(f"1ì°¨ ê²€ìƒ‰ ì„±ê³µ: '{used_q}' / ë°˜ê²½ {used_r}m / ê²°ê³¼ {len(base_results)}ê°œ")

        merged_results = base_results
        style_map: Dict[str, Dict] = {}
        expanded_queries: List[str] = []

        if use_review_expansion:
            candidates = base_results[:topn_for_review]
            area_hint = " ".join(address.strip().split()[:3]) or address.strip()

            with st.spinner("ì›¹ í›„ê¸°(ë¸”ë¡œê·¸/ì›¹ë¬¸ì„œ) ìŠ¤ë‹ˆí« ìˆ˜ì§‘ ì¤‘..."):
                snippets = {p.get("place_name", ""): build_review_snippet_for_place(p.get("place_name", ""), area_hint) for p in candidates if p.get("place_name", "")}

            with st.spinner("ì›¹ í›„ê¸° ê¸°ë°˜ ìœ ëª… ìŠ¤íƒ€ì¼ íƒœê·¸ ë¶„ì„(GPT)..."):
                style_map = analyze_styles_from_reviews_with_openai(
                    api_key=OPENAI_API_KEY,
                    chosen_query=chosen_query,
                    places=candidates,
                    review_snippets=snippets,
                )

            expanded_queries = build_expanded_queries_from_tags(chosen_query=chosen_query, style_map=style_map, max_queries=expansion_queries_n)

            if expanded_queries:
                with st.spinner("í™•ì¥ ê²€ìƒ‰ì–´ë¡œ ì¶”ê°€ ê²€ìƒ‰ ì¤‘..."):
                    extra_lists = []
                    for q in expanded_queries:
                        if auto_fallback:
                            res, _, _ = search_salons_with_fallback(chosen_query=q, x=x, y=y, radius_m=radius, size=result_size)
                            extra_lists.append(res)
                        else:
                            extra_lists.append(kakao_keyword_search(query=q, x=x, y=y, radius_m=radius, size=result_size, page=1))
                merged_results = merge_places(base_results, *extra_lists)

        st.success(f"ìµœì¢… ê²°ê³¼ {len(merged_results)}ê°œ")
        if expanded_queries:
            st.write("í™•ì¥ ê²€ìƒ‰ì–´(í›„ê¸° ê¸°ë°˜):", ", ".join(expanded_queries))

        map_points = [{"lat": float(r["y"]), "lon": float(r["x"])} for r in merged_results if r.get("x") and r.get("y")]
        if map_points:
            st.map(map_points, zoom=13)

        st.subheader("ë¯¸ìš©ì‹¤ ë¦¬ìŠ¤íŠ¸")
        for i, r in enumerate(merged_results, start=1):
            name = r.get("place_name", "")
            road = r.get("road_address_name", "") or r.get("address_name", "")
            phone = r.get("phone", "")
            dist = r.get("distance", "")
            url = r.get("place_url", "")

            st.markdown(f"### {i}. {name}")
            if dist:
                st.write(f"- ê±°ë¦¬: **{dist}m**")
            st.write(f"- ì£¼ì†Œ: {road}")
            if phone:
                st.write(f"- ì „í™”: {phone}")
            if url:
                st.write(f"- ì¹´ì¹´ì˜¤ë§µ: {url}")
            if use_review_expansion and name in style_map:
                tags = style_map[name].get("tags", [])
                summary = style_map[name].get("summary", "")
                if tags:
                    st.write("- ì›¹ í›„ê¸° ê¸°ë°˜ ìœ ëª… ìŠ¤íƒ€ì¼:", " / ".join(tags))
                if summary:
                    st.caption(f"í›„ê¸° ìš”ì•½: {summary}")

    except Exception as e:
        st.error(f"ì˜¤ë¥˜: {e}")

st.divider()

if st.button("ì „ì²´ ì„ íƒ/ê²°ê³¼ ì´ˆê¸°í™”", key="reset_all", type="secondary"):
    for k in keys:
        st.session_state[k] = None
    st.session_state["gpt_queries"] = []
    st.session_state["gpt_reasons"] = []
    st.rerun()
